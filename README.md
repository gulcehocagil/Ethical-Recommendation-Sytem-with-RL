# Ethical-Recommendation-Sytem-with-RL
This project focuses on developing a Responsible News Recommendation System using the Microsoft News Dataset (MIND). The primary goal is to address the challenge of balancing traditional recommendation performance with ethical considerations, specifically targeting the reduction of content toxicity and the promotion of information veracity.
This project implements a responsible news recommendation framework using the MIND (Microsoft News Dataset). It moves beyond traditional click-through rate (CTR) optimization by integrating ethical dimensions such as content toxicity and information veracity into the recommendation logic.Project OverviewThe core objective is to balance recommendation accuracy with content safety. By utilizing deep learning models to assess news quality, the system formulates the recommendation task as a multi-objective decision-making problem.Key FeaturesToxicity Analysis: Uses the unitary/toxic-bert model to calculate toxicity scores for news content.Veracity Detection: Employs the hamzab/roberta-fake-news-classification model to evaluate the likelihood of news being real or fake.Multi-Objective Scoring: Ranks news candidates based on a weighted combination of relevance, veracity, and toxicity.Performance Evaluation: Measures success using Hit Ratio (HR) and NDCG, alongside toxicity and veracity exposure metrics.Technical StackLanguage: PythonLibraries: pandas, numpy, torch, scikit-learnTransformers: Hugging Face pipeline for NLP tasksVisualization: matplotlib for trade-off analysisProject WorkflowData Preprocessing:Loading behavior and news datasets from the MIND dataset.Merging titles and abstracts to create a comprehensive text feature for each news item.Scoring & Labeling:Processing the first 5,000 news items through toxicity and veracity classifiers.Saving results into news_scores.csv for downstream recommendation tasks.Baseline Model:Implementing a popularity-based recommendation baseline.Evaluating initial HR@5 and NDCG@5 scores.Policy Optimization (Phase 4):A grid search is performed on weights for veracity ($w_{ver}$) and toxicity ($w_{tox}$).The formula used for ranking is: $Score = (w_{ver} \times Veracity) - (w_{tox} \times Toxicity)$.Pareto Frontier Analysis:Visualizing the trade-off between recommendation accuracy (Hit Ratio) and ethical exposure metrics.Identifying optimal policies that minimize toxicity without significantly degrading user experience.ResultsThe project identifies a "Best Policy" by calculating a selection score that balances accuracy, toxicity, and veracity. Detailed performance logs are exported to phase4_policy_grid_results.csv.
